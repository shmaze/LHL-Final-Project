{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"3-1_Recurrent-Neural-Networks-and-LSTM.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"5c8ead54"},"source":["In this notebook we will explore using a recurrent neural network (RNN) and long short term memory applications (LSTM) of the keras library to predict prices."],"id":"5c8ead54"},{"cell_type":"code","metadata":{"id":"33ba7b7d","executionInfo":{"status":"ok","timestamp":1638116723242,"user_tz":420,"elapsed":6,"user":{"displayName":"Joshua Maes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06250848103878308105"}}},"source":["# import libraries\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import xgboost as xgb\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, r2_score, mean_squared_error, mean_absolute_error, matthews_corrcoef, classification_report, roc_auc_score\n","from xgboost import XGBRegressor, XGBClassifier\n","from sklearn.model_selection import RepeatedKFold, cross_val_score, GridSearchCV\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from sklearn.decomposition import PCA\n","from sklearn.feature_selection import SelectKBest\n","import keras\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout"],"id":"33ba7b7d","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":73},"id":"LUweK71mn-OX","executionInfo":{"status":"ok","timestamp":1638116763608,"user_tz":420,"elapsed":33580,"user":{"displayName":"Joshua Maes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06250848103878308105"}},"outputId":"371ee62a-01af-4919-95d1-fe8096b2980d"},"source":["from google.colab import files\n","uploaded = files.upload()\n"],"id":"LUweK71mn-OX","execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-46146bd2-6083-4284-bb20-fe3d8af76fc4\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-46146bd2-6083-4284-bb20-fe3d8af76fc4\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving data_new_features.csv to data_new_features.csv\n"]}]},{"cell_type":"code","metadata":{"id":"GhfnWO2jnypY","executionInfo":{"status":"ok","timestamp":1638116764873,"user_tz":420,"elapsed":422,"user":{"displayName":"Joshua Maes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06250848103878308105"}}},"source":["# import our data \n","\n","data = pd.read_csv('data_new_features.csv')\n","\n"],"id":"GhfnWO2jnypY","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"dPIxpC36oQ0K","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1638116764873,"user_tz":420,"elapsed":6,"user":{"displayName":"Joshua Maes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06250848103878308105"}},"outputId":"f2cf77ad-a4d8-41fe-b167-6b400c5cb997"},"source":["data.head()"],"id":"dPIxpC36oQ0K","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>close</th>\n","      <th>Volume BTC</th>\n","      <th>Volume USDT</th>\n","      <th>7day_MA</th>\n","      <th>50day_MA</th>\n","      <th>200day_MA</th>\n","      <th>24h_vBTC</th>\n","      <th>24h_vUSDT</th>\n","      <th>Label</th>\n","      <th>7day_wma</th>\n","      <th>50day_wma</th>\n","      <th>200day_wma</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-09-26 12:00:00</td>\n","      <td>6452.115</td>\n","      <td>1543.675</td>\n","      <td>9997567.940</td>\n","      <td>6577.944583</td>\n","      <td>6561.698358</td>\n","      <td>7390.488019</td>\n","      <td>16023.490</td>\n","      <td>1.037709e+08</td>\n","      <td>1.0</td>\n","      <td>6527.313964</td>\n","      <td>6732.691616</td>\n","      <td>8070.491508</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2018-09-27 01:00:00</td>\n","      <td>6503.800</td>\n","      <td>1407.060</td>\n","      <td>9169317.600</td>\n","      <td>6579.006964</td>\n","      <td>6561.667300</td>\n","      <td>7389.493567</td>\n","      <td>16072.690</td>\n","      <td>1.041770e+08</td>\n","      <td>1.0</td>\n","      <td>6527.336299</td>\n","      <td>6732.291142</td>\n","      <td>8069.810691</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2018-09-27 02:00:00</td>\n","      <td>6512.935</td>\n","      <td>1391.140</td>\n","      <td>9050773.030</td>\n","      <td>6580.345119</td>\n","      <td>6561.588092</td>\n","      <td>7388.481150</td>\n","      <td>16143.985</td>\n","      <td>1.046955e+08</td>\n","      <td>0.0</td>\n","      <td>6527.463245</td>\n","      <td>6731.906202</td>\n","      <td>8069.133475</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2018-09-27 03:00:00</td>\n","      <td>6503.720</td>\n","      <td>1063.475</td>\n","      <td>6920079.985</td>\n","      <td>6581.489345</td>\n","      <td>6561.542342</td>\n","      <td>7387.513317</td>\n","      <td>15713.075</td>\n","      <td>1.019428e+08</td>\n","      <td>0.0</td>\n","      <td>6527.476457</td>\n","      <td>6731.506188</td>\n","      <td>8068.452214</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2018-09-27 04:00:00</td>\n","      <td>6496.275</td>\n","      <td>927.785</td>\n","      <td>6033148.635</td>\n","      <td>6582.556012</td>\n","      <td>6561.741625</td>\n","      <td>7386.502323</td>\n","      <td>15352.690</td>\n","      <td>9.962635e+07</td>\n","      <td>0.0</td>\n","      <td>6527.396652</td>\n","      <td>6731.094064</td>\n","      <td>8067.767648</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  date     close  ...    50day_wma   200day_wma\n","0  2018-09-26 12:00:00  6452.115  ...  6732.691616  8070.491508\n","1  2018-09-27 01:00:00  6503.800  ...  6732.291142  8069.810691\n","2  2018-09-27 02:00:00  6512.935  ...  6731.906202  8069.133475\n","3  2018-09-27 03:00:00  6503.720  ...  6731.506188  8068.452214\n","4  2018-09-27 04:00:00  6496.275  ...  6731.094064  8067.767648\n","\n","[5 rows x 13 columns]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"kENo9QB6od_7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638116766612,"user_tz":420,"elapsed":1742,"user":{"displayName":"Joshua Maes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06250848103878308105"}},"outputId":"3bea6cb8-7a89-49f9-9b97-9d0dc930ea63"},"source":["# we are going to continue with this as a classification problem, as we are most concerned with correctly predicting direction of bitcoin price movement\n","\n","data.data = data.date.apply(lambda x: pd.to_datetime(x))\n","\n","data.set_index('date', inplace=True)\n","\n","# set up train and testing sets\n","\n","test_size = 90 * 24    # 24 hourly periods per day\n","train_size = len(data.index) - test_size\n","\n","train = data[:train_size]\n","test = data[train_size:]\n","\n","X_train = train.drop('Label', axis=1)\n","X_test = test.drop('Label', axis=1)\n","y_train = train.Label\n","y_test = test.Label"],"id":"kENo9QB6od_7","execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}]},{"cell_type":"code","metadata":{"id":"hp6sOyL_qULg","executionInfo":{"status":"ok","timestamp":1638116766612,"user_tz":420,"elapsed":5,"user":{"displayName":"Joshua Maes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06250848103878308105"}}},"source":["# we are going to scale our data in this notebook prior to initializing our model\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","scaler = MinMaxScaler()\n","\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)"],"id":"hp6sOyL_qULg","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"zVNBPE5Wrni0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638116766612,"user_tz":420,"elapsed":4,"user":{"displayName":"Joshua Maes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06250848103878308105"}},"outputId":"0cceddd7-5e73-41a9-a837-366c6744c5ce"},"source":["X_train_scaled.shape"],"id":"zVNBPE5Wrni0","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(17372, 11)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"aJ9m9yFnx0sk","executionInfo":{"status":"ok","timestamp":1638116766613,"user_tz":420,"elapsed":4,"user":{"displayName":"Joshua Maes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06250848103878308105"}}},"source":["# in order to pass our data into an LSTM model we have to reshape it into a 3D array, in this first instance, we are going to use the previous 24 time steps to predict the following hour\n","\n","num_steps = 24\n","\n","# set up a list and convert to array taking previous observations timesteps into account\n","X_ = []\n","y_ = []\n","for i in range(24, X_train_scaled.shape[0]):\n","  X_.append(X_train_scaled[i-num_steps:i, 0])\n","  y_.append(y_train[i])\n","\n","X_train_final, y_train_final = np.array(X_), np.array(y_)\n","\n","X_t = []\n","y_t = []\n","for j in range(24, X_test_scaled.shape[0]):\n","  X_t.append(X_test_scaled[i-num_steps:j, 0])\n","  y_t.append(y_test[j])\n","\n","X_test_final, y_test_final = np.array(X_t), np.array(y_t)\n","\n","X_train_rs = np.reshape(X_train_final, (X_train_final.shape[0], X_train_final.shape[1], 1))\n","\n","X_test_rs = np.reshape(X_test_final, (X_test_final.shape[0], X_test_final.shape[1], 1))\n"],"id":"aJ9m9yFnx0sk","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"22wxz4ECrAS8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638116767305,"user_tz":420,"elapsed":695,"user":{"displayName":"Joshua Maes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06250848103878308105"}},"outputId":"a6206a4d-13a4-42b2-9d4e-f64c05794a00"},"source":["# initializing our model\n","\n","model = Sequential()\n","model.add(LSTM(units=30, activation='relu', return_sequences=True, input_shape=(X_train_rs.shape[1], 1)))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units=60, activation='relu', return_sequences=True))\n","model.add(Dropout(0.3))\n","model.add(LSTM(units=90, activation='relu', return_sequences=True))\n","model.add(Dropout(0.4))\n","model.add(LSTM(units=120, activation='relu', return_sequences=True))\n","model.add(Dropout(0.5))\n","model.add(Dense(units=1))\n","\n","model.summary()\n"],"id":"22wxz4ECrAS8","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 24, 30)            3840      \n","                                                                 \n"," dropout (Dropout)           (None, 24, 30)            0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 24, 60)            21840     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 24, 60)            0         \n","                                                                 \n"," lstm_2 (LSTM)               (None, 24, 90)            54360     \n","                                                                 \n"," dropout_2 (Dropout)         (None, 24, 90)            0         \n","                                                                 \n"," lstm_3 (LSTM)               (None, 24, 120)           101280    \n","                                                                 \n"," dropout_3 (Dropout)         (None, 24, 120)           0         \n","                                                                 \n"," dense (Dense)               (None, 24, 1)             121       \n","                                                                 \n","=================================================================\n","Total params: 181,441\n","Trainable params: 181,441\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"8QMYso3mBw7m","executionInfo":{"status":"ok","timestamp":1638116767305,"user_tz":420,"elapsed":6,"user":{"displayName":"Joshua Maes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06250848103878308105"}}},"source":["# now we will compile our model\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"id":"8QMYso3mBw7m","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnNZ7nVqEpBR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638135514754,"user_tz":420,"elapsed":18747452,"user":{"displayName":"Joshua Maes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06250848103878308105"}},"outputId":"47fecea2-5280-4b40-f55f-8af9bed983c6"},"source":["# set our history of model training\n","\n","history = model.fit(X_train_rs, y_train_final, epochs=500, batch_size=32, validation_split=0.15)"],"id":"xnNZ7nVqEpBR","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","461/461 [==============================] - 42s 80ms/step - loss: 0.8337 - accuracy: 0.4959 - val_loss: 0.7305 - val_accuracy: 0.4983\n","Epoch 2/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7172 - accuracy: 0.5011 - val_loss: 0.6976 - val_accuracy: 0.4983\n","Epoch 3/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7088 - accuracy: 0.5016 - val_loss: 0.6939 - val_accuracy: 0.5014\n","Epoch 4/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7064 - accuracy: 0.4996 - val_loss: 0.6937 - val_accuracy: 0.4983\n","Epoch 5/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7050 - accuracy: 0.5012 - val_loss: 0.7062 - val_accuracy: 0.5016\n","Epoch 6/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7052 - accuracy: 0.5001 - val_loss: 0.6962 - val_accuracy: 0.5016\n","Epoch 7/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7041 - accuracy: 0.5008 - val_loss: 0.6938 - val_accuracy: 0.5016\n","Epoch 8/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7042 - accuracy: 0.5004 - val_loss: 0.6952 - val_accuracy: 0.5016\n","Epoch 9/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7028 - accuracy: 0.5032 - val_loss: 0.6944 - val_accuracy: 0.4983\n","Epoch 10/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7026 - accuracy: 0.5021 - val_loss: 0.6958 - val_accuracy: 0.5017\n","Epoch 11/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7028 - accuracy: 0.5012 - val_loss: 0.6934 - val_accuracy: 0.4984\n","Epoch 12/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7026 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.5016\n","Epoch 13/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7027 - accuracy: 0.5015 - val_loss: 0.6949 - val_accuracy: 0.4983\n","Epoch 14/500\n","461/461 [==============================] - 36s 77ms/step - loss: 0.7021 - accuracy: 0.5019 - val_loss: 0.6934 - val_accuracy: 0.4983\n","Epoch 15/500\n","461/461 [==============================] - 36s 77ms/step - loss: 0.7019 - accuracy: 0.5025 - val_loss: 0.6960 - val_accuracy: 0.5017\n","Epoch 16/500\n","461/461 [==============================] - 36s 77ms/step - loss: 0.7014 - accuracy: 0.5032 - val_loss: 0.6932 - val_accuracy: 0.5009\n","Epoch 17/500\n","461/461 [==============================] - 36s 77ms/step - loss: 0.7018 - accuracy: 0.5013 - val_loss: 0.6932 - val_accuracy: 0.5016\n","Epoch 18/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7015 - accuracy: 0.5018 - val_loss: 0.6950 - val_accuracy: 0.5017\n","Epoch 19/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7014 - accuracy: 0.5014 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 20/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7017 - accuracy: 0.5011 - val_loss: 0.6934 - val_accuracy: 0.4983\n","Epoch 21/500\n","461/461 [==============================] - 36s 77ms/step - loss: 0.7013 - accuracy: 0.5028 - val_loss: 0.6932 - val_accuracy: 0.5016\n","Epoch 22/500\n","461/461 [==============================] - 36s 77ms/step - loss: 0.7010 - accuracy: 0.5021 - val_loss: 0.6933 - val_accuracy: 0.4984\n","Epoch 23/500\n","461/461 [==============================] - 36s 77ms/step - loss: 0.7016 - accuracy: 0.5003 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 24/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7008 - accuracy: 0.5013 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 25/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.7009 - accuracy: 0.5007 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 26/500\n","461/461 [==============================] - 36s 77ms/step - loss: 0.7000 - accuracy: 0.5016 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 27/500\n","461/461 [==============================] - 36s 77ms/step - loss: 0.6996 - accuracy: 0.5022 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 28/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6992 - accuracy: 0.5042 - val_loss: 0.6952 - val_accuracy: 0.5017\n","Epoch 29/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6988 - accuracy: 0.5017 - val_loss: 0.6932 - val_accuracy: 0.4984\n","Epoch 30/500\n","461/461 [==============================] - 36s 77ms/step - loss: 0.6980 - accuracy: 0.5035 - val_loss: 0.6935 - val_accuracy: 0.4983\n","Epoch 31/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6978 - accuracy: 0.5022 - val_loss: 0.6941 - val_accuracy: 0.4983\n","Epoch 32/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6975 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.5016\n","Epoch 33/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6967 - accuracy: 0.5034 - val_loss: 0.6933 - val_accuracy: 0.4984\n","Epoch 34/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6963 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.5009\n","Epoch 35/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6956 - accuracy: 0.5060 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 36/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6951 - accuracy: 0.5072 - val_loss: 0.6935 - val_accuracy: 0.4983\n","Epoch 37/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6951 - accuracy: 0.5064 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 38/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6948 - accuracy: 0.5048 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 39/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6944 - accuracy: 0.5071 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 40/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6942 - accuracy: 0.5064 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 41/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6938 - accuracy: 0.5076 - val_loss: 0.6993 - val_accuracy: 0.5017\n","Epoch 42/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6938 - accuracy: 0.5104 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 43/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6938 - accuracy: 0.5086 - val_loss: 0.6931 - val_accuracy: 0.5016\n","Epoch 44/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6932 - accuracy: 0.5125 - val_loss: 0.6933 - val_accuracy: 0.4983\n","Epoch 45/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6938 - accuracy: 0.5067 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 46/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6934 - accuracy: 0.5103 - val_loss: 0.6951 - val_accuracy: 0.5017\n","Epoch 47/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6934 - accuracy: 0.5092 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 48/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6933 - accuracy: 0.5111 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 49/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6930 - accuracy: 0.5145 - val_loss: 0.6931 - val_accuracy: 0.5017\n","Epoch 50/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6932 - accuracy: 0.5103 - val_loss: 0.6959 - val_accuracy: 0.5017\n","Epoch 51/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6930 - accuracy: 0.5139 - val_loss: 0.6948 - val_accuracy: 0.5017\n","Epoch 52/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6931 - accuracy: 0.5148 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 53/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6929 - accuracy: 0.5135 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 54/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6930 - accuracy: 0.5143 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 55/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6928 - accuracy: 0.5163 - val_loss: 0.6931 - val_accuracy: 0.5017\n","Epoch 56/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6929 - accuracy: 0.5141 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 57/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6928 - accuracy: 0.5181 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 58/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6928 - accuracy: 0.5154 - val_loss: 0.6944 - val_accuracy: 0.5017\n","Epoch 59/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6927 - accuracy: 0.5177 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 60/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.6945 - val_accuracy: 0.5017\n","Epoch 61/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6927 - accuracy: 0.5186 - val_loss: 0.6944 - val_accuracy: 0.5017\n","Epoch 62/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6927 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 63/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6926 - accuracy: 0.5186 - val_loss: 0.6950 - val_accuracy: 0.5017\n","Epoch 64/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6927 - accuracy: 0.5173 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 65/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6927 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 66/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5177 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 67/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5183 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 68/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6931 - val_accuracy: 0.5017\n","Epoch 69/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5178 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 70/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 71/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 72/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 73/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 74/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 75/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 76/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6944 - val_accuracy: 0.5017\n","Epoch 77/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 78/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 79/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 80/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 81/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 82/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6948 - val_accuracy: 0.5017\n","Epoch 83/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 84/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 85/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 86/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 87/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6946 - val_accuracy: 0.5017\n","Epoch 88/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 89/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 90/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 91/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 92/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 93/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 94/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 95/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 96/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 97/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 98/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 99/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6945 - val_accuracy: 0.5017\n","Epoch 100/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 101/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6927 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 102/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 103/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 104/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 105/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 106/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 107/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 108/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 109/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 110/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5177 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 111/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 112/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 113/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 114/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 115/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 116/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6945 - val_accuracy: 0.5017\n","Epoch 117/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 118/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 119/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 120/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 121/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6951 - val_accuracy: 0.5017\n","Epoch 122/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 123/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 124/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 125/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 126/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 127/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 128/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 129/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 130/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 131/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 132/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 133/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 134/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 135/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 136/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 137/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 138/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 139/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 140/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 141/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 142/500\n","461/461 [==============================] - 36s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 143/500\n","461/461 [==============================] - 36s 78ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 144/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 145/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 146/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 147/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 148/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 149/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6947 - val_accuracy: 0.5017\n","Epoch 150/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 151/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 152/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 153/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 154/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 155/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 156/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 157/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 158/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 159/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 160/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 161/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 162/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 163/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 164/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 165/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 166/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 167/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 168/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 169/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 170/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6946 - val_accuracy: 0.5017\n","Epoch 171/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 172/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 173/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 174/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 175/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 176/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 177/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 178/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 179/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 180/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 181/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 182/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 183/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 184/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 185/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 186/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 187/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6927 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 188/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 189/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 190/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 191/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 192/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 193/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 194/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 195/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 196/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 197/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 198/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 199/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 200/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 201/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 202/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 203/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 204/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 205/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6950 - val_accuracy: 0.5017\n","Epoch 206/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 207/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 208/500\n","461/461 [==============================] - 37s 79ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 209/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 210/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 211/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 212/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6944 - val_accuracy: 0.5017\n","Epoch 213/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 214/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 215/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 216/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 217/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 218/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 219/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 220/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 221/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 222/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 223/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6944 - val_accuracy: 0.5017\n","Epoch 224/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 225/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 226/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 227/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6947 - val_accuracy: 0.5017\n","Epoch 228/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 229/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 230/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 231/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 232/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 233/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 234/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 235/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 236/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 237/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 238/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 239/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 240/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 241/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 242/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 243/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 244/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 245/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 246/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 247/500\n","461/461 [==============================] - 38s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6946 - val_accuracy: 0.5017\n","Epoch 248/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 249/500\n","461/461 [==============================] - 37s 80ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 250/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 251/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6948 - val_accuracy: 0.5017\n","Epoch 252/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 253/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 254/500\n","461/461 [==============================] - 38s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 255/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 256/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 257/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 258/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 259/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 260/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 261/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 262/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 263/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 264/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 265/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 266/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 267/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 268/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 269/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 270/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 271/500\n","461/461 [==============================] - 38s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 272/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 273/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 274/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 275/500\n","461/461 [==============================] - 38s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 276/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 277/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 278/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 279/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 280/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 281/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 282/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 283/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 284/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6949 - val_accuracy: 0.5017\n","Epoch 285/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 286/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 287/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6945 - val_accuracy: 0.5017\n","Epoch 288/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 289/500\n","461/461 [==============================] - 37s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 290/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 291/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6924 - accuracy: 0.5174 - val_loss: 0.6950 - val_accuracy: 0.5017\n","Epoch 292/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6950 - val_accuracy: 0.5017\n","Epoch 293/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 294/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 295/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 296/500\n","461/461 [==============================] - 38s 81ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 297/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 298/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 299/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 300/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 301/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 302/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 303/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 304/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 305/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 306/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 307/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6945 - val_accuracy: 0.5017\n","Epoch 308/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 309/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 310/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 311/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 312/500\n","461/461 [==============================] - 38s 81ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 313/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 314/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 315/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 316/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 317/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 318/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 319/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 320/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 321/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 322/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 323/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6944 - val_accuracy: 0.5017\n","Epoch 324/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 325/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 326/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 327/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 328/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 329/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 330/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 331/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 332/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 333/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 334/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 335/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 336/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 337/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 338/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 339/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 340/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 341/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 342/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 343/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 344/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 345/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 346/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6945 - val_accuracy: 0.5017\n","Epoch 347/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 348/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 349/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 350/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 351/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 352/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 353/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 354/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 355/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 356/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 357/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6947 - val_accuracy: 0.5017\n","Epoch 358/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 359/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 360/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 361/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 362/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 363/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 364/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 365/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 366/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 367/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 368/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 369/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 370/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 371/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 372/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 373/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 374/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 375/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 376/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 377/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 378/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6927 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 379/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 380/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 381/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 382/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 383/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 384/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 385/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 386/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 387/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 388/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 389/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 390/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 391/500\n","461/461 [==============================] - 39s 85ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 392/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 393/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 394/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 395/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 396/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 397/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 398/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 399/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 400/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 401/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 402/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 403/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 404/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6951 - val_accuracy: 0.5017\n","Epoch 405/500\n","461/461 [==============================] - 38s 82ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 406/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 407/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 408/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 409/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 410/500\n","461/461 [==============================] - 39s 85ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 411/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 412/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 413/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 414/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 415/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 416/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 417/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6949 - val_accuracy: 0.5017\n","Epoch 418/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 419/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 420/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 421/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 422/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 423/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 424/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 425/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 426/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 427/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 428/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 429/500\n","461/461 [==============================] - 39s 85ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 430/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 431/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 432/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 433/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 434/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 435/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 436/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 437/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 438/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 439/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 440/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 441/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 442/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 443/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 444/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 445/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 446/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 447/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 448/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6945 - val_accuracy: 0.5017\n","Epoch 449/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 450/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 451/500\n","461/461 [==============================] - 39s 85ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 452/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 453/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6948 - val_accuracy: 0.5017\n","Epoch 454/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 455/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 456/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 457/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 458/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 459/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6944 - val_accuracy: 0.5017\n","Epoch 460/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 461/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 462/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 463/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 464/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6943 - val_accuracy: 0.5017\n","Epoch 465/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 466/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 467/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 468/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 469/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 470/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 471/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6944 - val_accuracy: 0.5017\n","Epoch 472/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 473/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 474/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 475/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 476/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 477/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 478/500\n","461/461 [==============================] - 40s 87ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 479/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5017\n","Epoch 480/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 481/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 482/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 483/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 484/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 485/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5017\n","Epoch 486/500\n","461/461 [==============================] - 38s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 487/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n","Epoch 488/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6944 - val_accuracy: 0.5017\n","Epoch 489/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 490/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6942 - val_accuracy: 0.5017\n","Epoch 491/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6940 - val_accuracy: 0.5017\n","Epoch 492/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 493/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 494/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5017\n","Epoch 495/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6941 - val_accuracy: 0.5017\n","Epoch 496/500\n","461/461 [==============================] - 38s 83ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6938 - val_accuracy: 0.5017\n","Epoch 497/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5017\n","Epoch 498/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6939 - val_accuracy: 0.5017\n","Epoch 499/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6925 - accuracy: 0.5189 - val_loss: 0.6935 - val_accuracy: 0.5017\n","Epoch 500/500\n","461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017\n"]}]},{"cell_type":"code","metadata":{"id":"mVxQdlzF5s2y","executionInfo":{"status":"ok","timestamp":1638209779632,"user_tz":420,"elapsed":3,"user":{"displayName":"Joshua Maes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06250848103878308105"}}},"source":["# Epoch 500/500\n","# 461/461 [==============================] - 39s 84ms/step - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6937 - val_accuracy: 0.5017 \n","\n","# results from LSTM model. This is not a very encouraging sign, as this is a similar accuracy we were achieving out of our xgboost classification models.\n","\n","# given the time and deadline provided, we are going to go with our previous results having over 60% confidence, as this gave us our desired minimum viable product accuracy of 55%\n","# after finishing presentation, will go back and attempt to achieve better results using different techniques. "],"id":"mVxQdlzF5s2y","execution_count":1,"outputs":[]}]}